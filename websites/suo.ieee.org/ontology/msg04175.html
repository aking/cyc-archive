<!-- MHonArc v2.4.8 -->
<!--X-Subject: RE: ONT RE: Ontology case study -->
<!--X-From-R13: Oqnz Brnfr <ncrnfrNxf.grxabjyrqtr.pbz> -->
<!--X-Date: Thu, 30 May 2002 14:40:15 &#45;0400 (EDT) -->
<!--X-Message-Id: 5.1.0.14.2.20020530104222.01eea5a8@ks.teknowledge.com -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: 679EBC1D3F201B449DCA00D50DEC7BE1057BCA@Monster.lb.pdit.intranet -->
<!--X-Reference: EBEMKBFIHNNPELLHDEKLEEMECCAA.chris_partridge@csi.com -->
<!--X-Head-End-->

<!-- /groups/802/3/efm/public/email/msg04175.html -->
<!-- /groups/???? ?SUO?                              -->

<HTML>

<HEAD>
<TITLE>RE: ONT RE: Ontology case study</TITLE>
<LINK REV="made" HREF="mailto:apease@ks.teknowledge.com">
</HEAD>

<BODY BGCOLOR="#FFFFFF">

<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->

<CENTER>

<TABLE CELLPADDING=3 CELLSPACING=0 BORDER=1 WIDTH="100%">
<TBODY>
<TR ALIGN="CENTER">
<TH COLSPAN=3><STRONG>Thread Links</STRONG></TH>
<TH COLSPAN=3><STRONG>Date Links</STRONG></TH>
</TR>
<TR ALIGN="CENTER">
<TD><A HREF="msg04160.html">Thread Prev</A>
</TD>
<TD><A HREF="msg04182.html">Thread Next</A>
</TD>
<TD><A HREF="thrd7.html#04175">Thread Index</A></Td>
<TD><A HREF="msg04176.html">Date Prev</A></TD>
<TD><A HREF="msg04174.html">Date Next</A>
</TD>
<TD><A HREF="mail7.html#04175">Date Index</A></TD>
</TR>
</TBODY>
</TABLE>
</CENTER>


<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h1>RE: ONT RE: Ontology case study</h1>
<hr>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<ul>
<li><em>To</em>: &lt;<A HREF="mailto:mail@ChrisPartridge.net">mail@ChrisPartridge.net</A>&gt;, &lt;<A HREF="mailto:ontology@ieee.org">ontology@ieee.org</A>&gt;</li>
<li><em>Subject</em>: RE: ONT RE: Ontology case study</li>
<li><em>From</em>: Adam Pease &lt;<A HREF="mailto:apease@ks.teknowledge.com">apease@ks.teknowledge.com</A>&gt;</li>
<li><em>Date</em>: Thu, 30 May 2002 11:40:50 -0700</li>
<li><em>In-Reply-To</em>: &lt;<a href="msg04147.html">EBEMKBFIHNNPELLHDEKLEEMECCAA.chris_partridge@csi.com</a>&gt;</li>
<li><em>References</em>: &lt;<a href="msg04141.html">679EBC1D3F201B449DCA00D50DEC7BE1057BCA@Monster.lb.pdit.intranet</a>&gt;</li>
<li><em>Sender</em>: <A HREF="mailto:owner-ontology@majordomo.ieee.org">owner-ontology@majordomo.ieee.org</A></li>
</ul>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
<hr>
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<PRE>

Chris,

At 10:03 PM 5/29/2002 +0200, Chris Partridge wrote:

&gt;I think the discussion that has developed on the difference between data 
&gt;models and ontologies is linked to Bill Anderson s original comment about 
&gt;the PAR his item 3). It also helps to answer the question Pierluigi 
&gt;Miraglia asked about why certain types of effort are less successful than 
&gt;it seems theoretically they should be. It also helps to answer Bill s 
&gt;point below where I (for once) take Adam s side.

I'm not sure which side that might be :-)


&gt;The issue is, it seems to me, accuracy and tolerance.
&gt;
&gt;Firstly, the kind of inference in things that the thread is labelling 
&gt;ontologies is absolute without any tolerance. As (real J) engineers know 
&gt;you need to plan for tolerance. An example I like is from (I think) Mike 
&gt;Uschold when building the 777 the errors in the individual tolerances add 
&gt;up leading to a visible difference in the length of the plane and 
&gt;associated problems. A philosopher has made the same point (see pp. 50-1 
&gt;of Dummett s The Logical Basis of Metaphysics 1991), that making 
&gt;inferences tends to dilute precision significantly. I copy the extract 
&gt;below for those that are interested.
&gt;
&gt;This means we need techniques to identify which inferences preserve enough 
&gt;accuracy to be workable. The way that this is done in operational systems 
&gt;is two-fold. One the requirements are clear the data is made sufficiently 
&gt;accurate for the specified process (and their inferences). That is why 
&gt;database people are always a bit wary of new processes one of the checks 
&gt;they apply is around data quality. In a system with unrestricted inference 
&gt;the data has to be unrestrictedly accurate i.e. exact.
&gt;
&gt;I also note, in passing, that FOL as it stands cannot do what Aristotle 
&gt;called practical reasoning no amount of logical/inferential processing 
&gt;will result in an action. This is not a problem in database systems.
&gt;
&gt;This leads onto another problem with what this discussion has labelled 
&gt;ontologies . The strong roots in predicate logic particularly FOL. As is 
&gt;well known (see e.g. p. 48 of Lowe s latest book) predicate logic was 
&gt;developed for mathematic applications and so is not well crafted for more 
&gt;mundane uses. For example, if you believe in a distinction between 
&gt;exemplification and attribution, this is not well marked and, at the very 
&gt;least, the temporality of predication needs some explaining. Note that 
&gt;database systems typically have this distinction built into them but in 
&gt;such a simplistic way that it cannot be practically used to reliably mark 
&gt;the distinction.
&gt;
&gt;How does this link to Bill s comment below about the potential for 
&gt;misinterpretation? Firstly, Bill is basically right, without some kind of 
&gt;framework, there will be misinterpretations. However, the work on 
&gt;ontologies may be able to reduce the potential significantly. It seems to 
&gt;me that if one can develop a well founded top ontology that this 
&gt;significantly reduces the potential for some kinds of misinterpretation 
&gt;(NB neither Cyc nor SUMO seem to currently have this).

Certainly any set of precise definitions that one adds to an existing model 
will help to reduce potential misinterpretation.  One might argue that Cyc 
or SUMO don't do this *sufficiently* with respect to some criteria, or that 
there are some other disadvantages involved in their use, but not that they 
don't add specificity and reduce potential minterpretation.

&gt;It also seems to me that the domain ontologies also need to be more 
&gt;rigourous. Just as the introduction of databases forced an increased level 
&gt;of accuracy so the sharing of databases (or ontologies) will force a 
&gt;further increase. In the area that I am interested in enterprise 
&gt;ontologies - it seems to me that both Cyc and SUMO are not sufficiently 
&gt;accurate. Of course, Cyc is intended to do common sense reasoning not 
&gt;database integration a different problem, and so has not need for accuracy 
&gt;along this dimension.

Forgive me for being a bit pointed, but I continue to be very troubled by 
claims that appear to me unjustified, unspecific or unsupported on this 
list.  If you believe Cyc and SUMO are &quot;not sufficiently accurate&quot;, what 
metric is that in regard to?  Is there a particular axiom in either that 
you could point out that would lead to an incorrect or inaccurate 
conclusion during the course of logical deduction?

&gt;
&gt;It seems to me that if we are looking for the kind of general ontologies 
&gt;that Bill suspects are not feasible, then we need to address the demands 
&gt;of accuracy and regimentation at both the top and domain levels. In my 
&gt;view, for the kind of applications that fall under Bill Anderson s 3), it 
&gt;is only really possible to do these together.

Indeed.  How would you suggest that we proceed, or proceed differently?

Adam


&gt;Regards,
&gt;
&gt;Chris
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;pp. 50-1 - Dummett, M. The Logical Basis of Metaphysics 1991.
&gt;
&gt;In a section called Degeneration of Probabilities .
&gt;
&gt;Hence it is sufficient, for mathematical purposes, that a principle of 
&gt;inference should guarantee that truth is transmitted from premises to 
&gt;conclusion. Outside mathematics, we have a motive to demand more, if we 
&gt;can get it. ... Most of our beliefs are perforce based upon grounds that 
&gt;fall short of being conclusive, but a form of inference guaranteed to 
&gt;preserve truth is not, in general, guaranteed to preserve degree of 
&gt;probability. ... The 'ideal' subject starting from beliefs whose 
&gt;probability is close to 1, will end up with beliefs negligibly greater 
&gt;than 0; the man of common sense, initially adopting beliefs with a much 
&gt;weaker evidential basis, but reasoning from them only to a meagre extent, 
&gt;will finish with far fewer beliefs than he. That is why scientific 
&gt;conclusions arrived at by long chains of impeccable reasoning almost 
&gt;always prove, when a direct test becomes possible, to be wrong. ... In 
&gt;practical life, truth is valued chiefly as a guide to action; and then the 
&gt;principal remedy for the degeneration of probability in the course of 
&gt;inferential reasoning is to employ it sparingly.
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;
&gt;-----Original Message-----
&gt;From: owner-ontology@majordomo.ieee.org 
&gt;[<A  HREF="mailto:owner-ontology@majordomo.ieee.org]On">mailto:owner-ontology@majordomo.ieee.org]On</A> Behalf Of William Burkett
&gt;Sent: 29 May 2002 17:15
&gt;To: 'Adam Pease'
&gt;Cc: ontology@ieee.org
&gt;Subject: ONT RE: Ontology case study
&gt;
&gt;
&gt;
&gt;Hi, Adam --
&gt;
&gt; &gt; &gt; -----Original Message-----
&gt; &gt; &gt; &gt; From: Adam Pease [<A  HREF="mailto:apease@ks.teknowledge.com">mailto:apease@ks.teknowledge.com</A>]
&gt; &gt; &gt; &gt; Sent: Thursday, May 23, 2002 2:10 PM
&gt; &gt; &gt; &gt; To: William Burkett; ontology@ieee.org
&gt; &gt; &gt; &gt; Subject: RE: Ontology case study
&gt; &gt; &gt;...
&gt; &gt; &gt; &gt; &gt;*The* most significant problem with this paradigm, however, is the
&gt; &gt; &gt; &gt; &gt;development and application of mappings.  What is &quot;mapping&quot;, 
&gt; really?  Can
&gt; &gt; &gt; &gt; &gt;it be understood and taught to the general ontology-using 
&gt; public?  Your
&gt; &gt; &gt; &gt; &gt;effort was successful because you were dealing with a closed 
&gt; system of a
&gt; &gt; &gt; &gt; &gt;known and well-defined scope and data meanings.  How can the mapping
&gt; &gt; &gt; &gt; &gt;lessons you learned (and were learned in the above efforts) be 
&gt; applied to
&gt; &gt; &gt; &gt; &gt;an open system with a huge, unknown, and constantly evolving scope 
&gt; and
&gt; &gt; &gt; &gt; &gt;fuzzy, ambiguous, context-sensitive data meanings?
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; The mapping problem is significant, to be sure, but is a problem in 
&gt; any
&gt; &gt; &gt; &gt; sort of integration effort, whether using ontologies, or a more
&gt; &gt; &gt; &gt; conventional data warehouse approach.  I would suggest that at 
&gt; least the
&gt; &gt; &gt; &gt; problem is more manageable than typical systems integration approaches
&gt; &gt; &gt; &gt; where n components require n^2 mappings.
&gt; &gt; &gt;
&gt; &gt; &gt;While I agree that mapping is an issue regardless of the integration
&gt; &gt; &gt;paradigm/approach used (e.g., neutral model, data warehouse, database
&gt; &gt; &gt;federations), I don't agree that the neutral model offers any advantages
&gt; &gt; &gt;in terms of manageability.  In fact, I think the problem is actually far
&gt; &gt; &gt;more complex and less manageable than n^2 direct mappings.  Sure, you
&gt; &gt; &gt;reduce the number of mappings to 2 * n, but then you have to
&gt; &gt; deal with:
&gt; &gt; &gt;
&gt; &gt; &gt;   - loss of semantic precision when &quot;generalizing&quot; local data into the
&gt; &gt; &gt; neutral model, making extraction (interpretation) of meaning in the
&gt; &gt; &gt; neutral model by other connected data source imprecise or wrong.
&gt; &gt;
&gt; &gt; That could be a problem if the neutral model is not specific or detailed
&gt; &gt; enough.  That needn't be the case however.
&gt;
&gt;I feel I should respond to this indirectly, because - on reading your 
&gt;other responses - I feel that the following observation is the source of 
&gt;many of our differences of opinion.
&gt;
&gt;I think that our differences stem from differing assumptions about how an 
&gt;upper ontology is to be or will be used (a neutral integration model being 
&gt;one such use.)  Your statement here implies that it is *possible* to be 
&gt;detailed and specific enough that the upper ontology/neutral model either 
&gt;cannot or will not be misused.  (Matthew, in his response, makes the same 
&gt;assumption.)  I feel this assumption is -- forgive me for saying and I 
&gt;intend no offense -- both naive and dogmatic.  If &quot;people&quot; use the upper 
&gt;ontology/neutral model at all, they WILL misuse it and interpret it to 
&gt;their own needs - knowingly or unknowingly.  All of my data modelling 
&gt;experience leads me to this position.
&gt;
&gt;I envision a bunch of different communities of people creating a bunch of 
&gt;ontologies and mapping them together following some standardized protocols 
&gt;such that a &quot;knowledge web&quot; can be built up incrementally as people do 
&gt;their jobs locally (like the internet has grown based on a few standard 
&gt;protocols).  I suspect that your vision is not dissimilar, though I cannot 
&gt;imagine what safeguards or procedures could possibly be put in place to 
&gt;prevent misuse of an upper ontology without some single overseeing arbiter 
&gt;to police its use.  (I also don't know if this &quot;knowledge web&quot; is the same 
&gt;thing as the &quot;Semantic Web&quot;, though it's as valid an interpretation or 
&gt;vision as any.)
&gt;
&gt;Perhaps another important differing assumption is that you/Matthew 
&gt;assumption computing or modelling professionals will be interpreting the 
&gt;upper ontology/neutral model and, therefore, have the responsibility of 
&gt;using it correctly.  I can't argue with this.  My assumption, however, is 
&gt;that Joe Everyman can pick it up, use it, or create his own ontology if he 
&gt;wants to get what he knows into a computer.
&gt;
&gt;We want the cost-of-entry for using an upper ontology to be low, 
&gt;right?  We can't, therefore, assume or depend on people using it 
&gt;correctly; rather, we should build in the safe-fail features to make sure 
&gt;that when it fails, such a fail isn't disastrous and recovery operations 
&gt;can be immediately started.
&gt;
&gt; &gt;
&gt; &gt; &gt;   - Mapping &quot;data source A&quot; -&gt; &quot;neutral model NM&quot; and &quot;data source B&quot; -&gt;
&gt; &gt; &gt; &quot;neutral model NM&quot; is not the same mapping &quot;data source A + B&quot; -&gt;
&gt; &gt; &gt; &quot;neutral model NM&quot;.  If there's an overlap of information in A and B,
&gt; &gt; &gt; there's a kind of &quot;information multiplexing&quot; involved that makes correct
&gt; &gt; &gt; mapping more difficult.
&gt; &gt;
&gt; &gt; I'm not sure I understand.  Could you provide an example?
&gt;
&gt;
&gt;
&gt;Suppose I map data from a local driver's registration database (data 
&gt;source A) into state government database for motor-voter registration 
&gt;(data source NM).  Suppose then that data from the Department of Motor 
&gt;Vehicles (data source B) is also mapped into the state database.  If 
&gt;William Burkett in Los Angeles is translated from A into NM, there will be 
&gt;a motor-voter record for that individual created.  If William C. Burkett 
&gt;from Los Angeles County is mapped from data source C into NM, then is a 
&gt;new motor-voter individual record created?  If I'd had prior knowledge of 
&gt;the two data sources - A and B - I could write mapping rules that take 
&gt;into account the fact that data source A doesn't use middle initials and 
&gt;that if (1) first name-last name and (2) city is in county, the it's one 
&gt;and the same individual.  If A and B are both mapped independantly of the 
&gt;knowledge of the other, it's very likely that there will be two records 
&gt;for the same individual in the NM.
&gt;
&gt;
&gt;
&gt; &gt;
&gt; &gt; &gt;   - Mapping between A and B is straight-forward because the &quot;system&quot; is
&gt; &gt; &gt; essentially closed: you know what is in A and what is in B.  Mapping 
&gt; A to
&gt; &gt; &gt; a NM is less deterministic: you *think* you know what is in NM, but if
&gt; &gt; &gt; others are free to map to it, their interpretation of what is in the NM
&gt; &gt; &gt; will likely be very different from yours.  In other words, the 
&gt; assumption
&gt; &gt; &gt; that all mappers will interpret the NM in the same way while mapping is
&gt; &gt; &gt; false. (Hell - the assumption that any two people will interpret *any*
&gt; &gt; &gt; model the same way is probably false, too.)
&gt; &gt;
&gt; &gt; I believe this is actually a good counterexample.  While the terms and
&gt; &gt; relations in a database representation don't have a formal semantics (note
&gt; &gt; that I didn't say SQL itself doesn't have a formal semantics), axiomatized
&gt; &gt; terms and relations in first order logic do.  The axioms  completely 
&gt; specify
&gt; &gt; the meaning of the term so there is not as much of an issue about people's
&gt; &gt; different interpretations.  Of course, if the axioms are not detailed or
&gt; &gt; specific enough that's a problem just as it would be with any
&gt; &gt; underspecified representation.
&gt;
&gt;I think THE most important issue is people's different 
&gt;interpretations.  (See my second assumption above.)  Regardless of the FOL 
&gt;language chosen to represent the ontology, human beings are still going to 
&gt;read the words/terms that are tokens in the FOL representation and apply 
&gt;natural language interpretations to them.  There is no getting away from 
&gt;this -- we are trapped using natural language - ultimately - to articulate 
&gt;and interpret meaning (i.e., real world domain semantics).
&gt;
&gt;
&gt;
&gt; &gt; &gt;   - When a new &quot;node&quot; is added to the community of integrated &quot;nodes&quot;
&gt; &gt; &gt; mapped to a common NM, the mappings of all the nodes need to be reviewed
&gt; &gt; &gt; to see if they still &quot;interpret&quot; the NM properly given the expansion of
&gt; &gt; &gt; its semantic applicability with/for the new node.
&gt; &gt;
&gt; &gt; I would have to disagree with this as well.  The interpretation of a term
&gt; &gt; does not change just because some additional term is added to the
&gt; &gt; ontology.  All the past mappings would still be correct.  The only issue
&gt; &gt; would be whether the mappings are specific enough and take appropriate
&gt; &gt; advantage of the presence of a new term.
&gt;
&gt;I guess we'll have to settle for the old &quot;agree to disagree&quot; conclusion, 
&gt;then, because my fundamental assumptions lead me to the opposite 
&gt;position.  I think it is very likely, in not inevitable, that the 
&gt;interpretation of a new term could cause &quot;interpretive ripples&quot; through a 
&gt;collection of mapped ontologies.  It's the same phenomena as a new person 
&gt;coming into your committee meeting half-way through: there's a temporary 
&gt;pertubation of the discussion while the new person &quot;comes up to speed&quot; 
&gt;with what's transpired so that he/she can then fully and fruitfully 
&gt;participate and contribute.
&gt;
&gt;
&gt;
&gt; &gt;
&gt; &gt; &gt;Off the top of my head, these are just some of the problems with a 
&gt; neutral
&gt; &gt; &gt;model integration approach.  These problems can be overcome
&gt; &gt; &gt;methodologically, of course, but the depth and dimensions of the problem
&gt; &gt; &gt;are, I think, still poorly understood (if not mostly unrecognized).
&gt; &gt; &gt;
&gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt;While I think you can sell the neutral ontology integration model 
&gt; as a
&gt; &gt; &gt; &gt; &gt;problem solving approach, getting people to know about and use 
&gt; SUMO (or
&gt; &gt; &gt; &gt; &gt;any other &quot;upper&quot; ontology) as neutral ontology in their solution 
&gt; is a
&gt; &gt; &gt; &gt; &gt;different kind of sales job altogether.  And it is one that I 
&gt; don't think
&gt; &gt; &gt; &gt; &gt;will be very successful - any well-defined and well-bounded 
&gt; integration
&gt; &gt; &gt; &gt; &gt;effort will want to use their own.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Can you discuss further why you feel they'd want to use their 
&gt; own?  I've
&gt; &gt; &gt; &gt; found that unlike in the research world, people who want to 
&gt; accomplish a
&gt; &gt; &gt; &gt; practical commercial task are very happy to adopt someone else's 
&gt; models or
&gt; &gt; &gt; &gt; software if it helps them get their job done.
&gt; &gt; &gt;
&gt; &gt; &gt;But in adopting someone else's models or software, how often do they use
&gt; &gt; &gt;them exactly as is?  I don't know how often I've heard &quot;My/our
&gt; &gt; &gt;requirements are different&quot;.  At the very best, they would use the
&gt; &gt; &gt;models/software as a starting point for doing what they want to
&gt; &gt; &gt;do.  Adopting and adapting a neutral ontology model to the usage and 
&gt; needs
&gt; &gt; &gt;of your local (integrated) community defeats the whole purpose of 
&gt; using it
&gt; &gt; &gt;as a generalized integration model.  People will interpret and use the
&gt; &gt; &gt;model as they wish, and this can't be policed (and shouldn't because 
&gt; it is
&gt; &gt; &gt;not wrong of them do this - it's natural.)  The only way &quot;standardized&quot;
&gt; &gt; &gt;interpretations will arise is by the conventions that arise and are
&gt; &gt; &gt;reinforced in a language-use community, in which case it will pay for
&gt; &gt; &gt;people to interpret the ontology the same way.  (Remember: dictionaries
&gt; &gt; &gt;don't specify the meaning of words; they document the conventional
&gt; &gt; &gt;meanings of usages of a word.)
&gt; &gt;
&gt; &gt; Well, we're drawing on the anecdotes of personal experience here, not
&gt; &gt; having the results of some survey that specifies how various groups of
&gt; &gt; people use various types of software.
&gt;
&gt;True enough.  I know of little realistic &quot;research studies&quot; in this field.
&gt;
&gt; &gt;I would only try to support my view
&gt; &gt; further with the fact that the vast majority of Java programmers use, and
&gt; &gt; subclass the JDK, rather than feeling a need to modify it.
&gt;
&gt;And my view stems from a different set of experiences, e.g., modelling the 
&gt;information requirements of domain experts for the purpose of representing 
&gt;and exchanging data between CAD systems.  My response to your Java example 
&gt;is that Java and the behavior of computing machines is a (relatively) 
&gt;well-understood domain compared to the knowledge in the &quot;real 
&gt;world&quot;.  Therefore the programmers that subclass the JDK already know what 
&gt;the classes could/should do and how to apply them.  You give the same 
&gt;programmers a class diagram ostensbility representing domain knowledge, 
&gt;like people or parts or products, and they will each interpret them - 
&gt;differently - as they see fit in their applications.  (Again - that has 
&gt;been my consistent and unvarying experience.)
&gt;
&gt;
&gt;
&gt;--- Bill

Adam Pease
Teknowledge
(650) 424-0500 x571

</PRE>

<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
<hr>
<ul><li><strong>Follow-Ups</strong>:
<ul>
<li><strong><a name="04182" href="msg04182.html">RE: ONT RE: Ontology case study</a></strong>
<ul><li><em>From:</em> &quot;Chris Partridge&quot; &lt;mail@ChrisPartridge.net&gt;</li></ul></li>
</ul></li></ul>
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="04141" href="msg04141.html">ONT RE: Ontology case study</a></strong>
<ul><li><em>From:</em> William Burkett &lt;WBurkett@PDIT.com&gt;</li></ul></li>
<li><strong><a name="04147" href="msg04147.html">RE: ONT RE: Ontology case study</a></strong>
<ul><li><em>From:</em> &quot;Chris Partridge&quot; &lt;chris_partridge@csi.com&gt;</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
<ul>
<LI>Prev by Date:
<STRONG><A HREF="msg04176.html">ONT Re: Data Models, Ontologies, Logic</A></STRONG>
</LI>
<LI>Next by Date:
<STRONG><A HREF="msg04174.html">Re: ONT RE: Ontology case study</A></STRONG>
</LI>
<li>Prev by thread:
<strong><a href="msg04160.html">RE: ONT RE: Ontology case study</a></strong>
</li>
<li>Next by thread:
<strong><a href="msg04182.html">RE: ONT RE: Ontology case study</a></strong>
</li>
<li>Index(es):
<ul>
<li><a href="mail7.html#04175"><strong>Date</strong></a></li>
<li><a href="thrd7.html#04175"><strong>Thread</strong></a></li>
</ul>
</li>
</ul>

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
</body>
</html>
