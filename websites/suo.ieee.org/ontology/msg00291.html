<!-- MHonArc v2.4.8 -->
<!--X-Subject: SUO: Re: Inquiry Driven Systems -->
<!--X-From-R13: Xba Ojoerl <wnjoerlNbnxynaq.rqh> -->
<!--X-Date: Sat, 6 Jan 2001 15:23:26 &#45;0500 (EST) -->
<!--X-Message-Id: 3A577941.43748384@oakland.edu -->
<!--X-Content-Type: text/plain -->
<!--X-Reference: 3A548BD0.FDBD1AB6@oakland.edu -->
<!--X-Reference: 3A549D23.653EB204@oakland.edu -->
<!--X-Reference: 3A54CB79.603E3F4D@oakland.edu -->
<!--X-Reference: 3A552141.DC7FFDFF@oakland.edu -->
<!--X-Reference: 3A5651F1.F10BEFD8@oakland.edu -->
<!--X-Head-End-->

<!-- /groups/802/3/efm/public/email/msg00291.html -->
<!-- /groups/???? ?SUO?                              -->

<HTML>

<HEAD>
<TITLE>SUO: Re: Inquiry Driven Systems</TITLE>
<LINK REV="made" HREF="mailto:jawbrey@oakland.edu">
</HEAD>

<BODY BGCOLOR="#FFFFFF">

<!--X-Body-Begin-->
<!--X-User-Header-->
<!--X-User-Header-End-->
<!--X-TopPNI-->

<CENTER>

<TABLE CELLPADDING=3 CELLSPACING=0 BORDER=1 WIDTH="100%">
<TBODY>
<TR ALIGN="CENTER">
<TH COLSPAN=3><STRONG>Thread Links</STRONG></TH>
<TH COLSPAN=3><STRONG>Date Links</STRONG></TH>
</TR>
<TR ALIGN="CENTER">
<TD><A HREF="msg00289.html">Thread Prev</A>
</TD>
<TD><A HREF="msg01535.html">Thread Next</A>
</TD>
<TD><A HREF="thrd82.html#00291">Thread Index</A></Td>
<TD><A HREF="msg00292.html">Date Prev</A></TD>
<TD><A HREF="msg00290.html">Date Next</A>
</TD>
<TD><A HREF="mail85.html#00291">Date Index</A></TD>
</TR>
</TBODY>
</TABLE>
</CENTER>


<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->
<h1>SUO: Re: Inquiry Driven Systems</h1>
<hr>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->
<UL>
<LI><em>To</em>: Stand Up Ontology &lt;<A HREF="mailto:standard-upper-ontology@ieee.org">standard-upper-ontology@ieee.org</A>&gt;</LI>
<LI><em>Subject</em>: SUO: Re: Inquiry Driven Systems</LI>
<LI><em>From</em>: Jon Awbrey &lt;<A HREF="mailto:jawbrey@oakland.edu">jawbrey@oakland.edu</A>&gt;</LI>
<LI><em>Date</em>: Sat, 06 Jan 2001 15:00:01 -0500</LI>
<LI><em>References</em>: &lt;<A HREF="msg00272.html">3A548BD0.FDBD1AB6@oakland.edu</A>&gt; &lt;<A HREF="msg00273.html">3A549D23.653EB204@oakland.edu</A>&gt; &lt;<A HREF="msg00276.html">3A54CB79.603E3F4D@oakland.edu</A>&gt; &lt;<A HREF="msg00279.html">3A552141.DC7FFDFF@oakland.edu</A>&gt; &lt;<A HREF="msg00289.html">3A5651F1.F10BEFD8@oakland.edu</A>&gt;</LI>
<LI><em>Reply-To</em>: Jon Awbrey &lt;<A HREF="mailto:jawbrey@oakland.edu">jawbrey@oakland.edu</A>&gt;</LI>
<LI><em>Sender</em>: <A HREF="mailto:owner-standard-upper-ontology@ieee.org">owner-standard-upper-ontology@ieee.org</A></LI>
</UL>
<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
<hr>
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<PRE>

¤~~~~~~~~~¤~~~~~~~~~¤~~~~~~~~~¤~~~~~~~~~¤~~~~~~~~~¤

Inquiring Minds,

This selection explains the notion of a "knowledge field" (KF) and
brings us back through the point where we first came in, with the
problematics that are classically illustrated in Plato's 'Meno'.

¤~~~~~~~~~¤~~~~~~~~~¤~ARCHIVE~SOURCES~¤~~~~~~~~~¤~~~~~~~~~¤

[ Document History:
| Project:  Intelligent Dynamic Systems Engineering
| Heading:  Original Interest Statement
| Authors:  Jon Awbrey
| Version:  Draft 5
| Created:  1991-Nov-12
| Revised:  1992-Sep-01
| Revised:  2001-Jan-06
| Setting:  Oakland University, Rochester, Michigan
| Excerpt:  Pages 4-7
]

1.1.2.1  Vector Field &amp; Control System

Dynamically, as in a control system, intelligence is a decision process that
selects an indicator of a tangent vector to follow at a point or a descriptor
of a corresponding operator to apply at a point.  The pointwise indicators
or descriptors can be any relevant signs or symbolic expressions:  names,
code numbers, address pointers, or quoted phrases.  A "vector field" attaches
to each point of phase space a single tangent vector or differential operator.
The "control system" is viewed as a ready generalization of a vector field, in
which whole sets of tangent vectors or differential operators are attached to
each point of phase space.  The "strategy" or "policy problem" of a controller
is to pick out one of these vectors to actualize at each point in accord with
reaching a given target or satisfying a given property.  An individual control
system is specified by information attached to each dynamic point that defines
a subset of the tangent space at that point.  This pointwise defined subset is
called "the indicatrix of permissible velocities" by (Arnold, 1986, ch. 11).

In the usage needed for combining AI and control systems to obtain
autonomous intelligent systems, it is important to recognize that the
pointwise indicators and descriptors must eventually have the character
of symbolic expressions existing in a language of non-trivial complexity.
Relating to this purpose, it does not really matter if their information
is viewed as represented in the states of discrete machines or in the
states of physical systems to which real and complex valued measurements
are attributed.  What makes the system of indications and descriptions
into a language is that its elements obey specific sets of axioms that
come to be recognized as characterizing interesting classes of symbol
systems.  Later on I will indicate one very broad definition of signs 
and symbol systems that I favor.  I find that this conception of signs
and languages equips the discussion of intelligent systems with an
indispensable handle on the levels of complexity that arise in their
description, analysis, and clarification.

1.1.2.2  Fields of Information &amp; Knowledge

Successive extensions of the vector field concept can be achieved by 
generalizing the form of pointwise information defined on a phase space.
A subset of a tangent space at a point can be viewed as a boolean-valued
function there, and as such can be generalized to a probability distribution
that is defined on the tangent space at that point.  This type of probabilistic
vector field or "information field" founds the subject of stochastic differential
geometry and its associated dynamic systems.  An alternate development in this
spirit might embody pointwise information about tangent vectors in the form of
linguistic expressions and ultimately in knowledge bases with the character of
empirical summaries or logical theories attached to each point of a phase space.

It is convenient to bring together under the heading of a "knowledge field" any
form of pointwise information, symbolic or numerical, concrete or theoretical,
that constrains the set of pointwise tangent vectors defined on a phase space.
In computational settings this information can be procedural and declarative
program code augmented by statistical and qualitative data.  In computing
applications a knowledge field acquires an aptly suggestive visual image:
bits and pieces of code and data elements sprinkled on a dynamic surface,
like bread crumbs to be followed through a forest.  The rewards and dangers
of so literally a "distributed" manner of information storage are extremely
well-documented (Hansel &amp; Gretel, n.d.), but there are times when it provides
the only means available.

1.1.2.3  The Trees &amp; The Forest

A sticking point of the whole discussion has just been
reached.  In the idyllic setting of a knowledge field the
question of systematic inquiry takes on the following form:

What piece of code should be followed in order to discover that code?

It is a classic catch, whose pattern was traced out long ago in the paradox
of Plato's 'Meno'.  Discussion of this dialogue and of the task it sets for
AI, cognitive science, education, including the design of intelligent tutoring
systems, can be found in (H. Gardner, 1985), (Chomsky, 1965, '72, '75, '80, '86),
(Fodor, 1975, 1983), (Piattelli-Palmarini, 1980), and in (Collins &amp; Stevens, 1991).
Though it appears to mask a legion of diversions, this text will present itself at
least twice more in the current engagement, both on the horizon and at the gates
of the project to fathom and to build intelligent systems.  Therefore, it is
worth recalling how this inquiry begins.  The interlocutor Meno asks:

| Can you tell me, Socrates, whether virtue can be taught,
| or is acquired by practice, not teaching?  Or if neither
| by practice nor by learning, whether it comes to mankind
| by nature or in some other way?  (Plato, 'Meno', p. 265).

Whether the word "virtue" (arete) is interpreted to mean virtuosity
in some special skill or a more general excellence of conduct, it is
evidently easy, in the understandable rush to "knowledge", to forget
or to ignore what the primary subject of this dialogue is.  Only when
the difficulties of the original question, whether virtue is teachable,
have been moderated by a tentative analysis does knowledge itself become
a topic of the conversation.  This hypothetical mediation of the problem
takes the following tack:  If virtue were a kind of knowledge, and if
every kind of knowledge could be taught, would it not follow that
virtue could be taught?

For the present purpose, it should be recognized that this "trial factorization"
of a problem space or phenomenal field is an important intellectual act in itself,
one that deserves attention in the effort to understand the competencies that
support intelligent functioning.  It is a good question to ask just what sort
of reasoning processes might be involved in the ability to find such a middle
term, as is served by "knowledge" in the example at hand.  Generally speaking,
interest will reside in a whole system of middle terms, which might be called
a "medium" of the problem domain or the field of phenomena.  This usage makes
plain the circumstance that the very recognition and expression of a problem
or phenomenon is already contingent upon and complicit with a particular set
of hypotheses that will inform the direction of its resolution or explanation.

One of the chief theoretical difficulties that obstructs the unification of
logic and dynamics in the study of intelligent systems can be seen in relation
to this question of how an intelligent agent might generate tentative but plausible
analyses of problems that confront it.  As described here, this requires a capacity
for identifying middle grounds that ameliorate or mollify a problem.  This facile
ability does not render any kind of demonstrative argument to be trusted in the
end and for all time, but is a temporizing measure, a way of locating test media
and of trying cases in the media selected.  It is easy to criticize such practices,
to say that every argument should be finally cast into a deductively canonized form,
harder to figure out how to live in the mean time without using such half-measures
of reasoning.  There is a line of thinking, extending from this reference point
in Plato through a glancing remark by Aristotle to the notice of C.S. Peirce,
which holds that the form of reasoning required to accomplish this feat is
neither inductive nor deductive and reduces to no combination of the two,
but is an independent type.
 
Aristotle called this form of reasoning "apagogy" ('Prior Analytics', 2.25)
and it was variously translated throughout the Middle Ages as "reduction" or
"abduction".  The sense of "reduction" here is just that by which one question
or problem is said to reduce to another, as in the AI strategy of goal reduction.
Abductive reasoning is also involved in the initial creation or apt generation of
hypotheses, as in diagnostic reasoning.  Thus, it is natural that abductive reasoning
has periodically become a topic of interest in AI and cognitive modeling, especially
in the effort to build expert systems that simulate and assist diagnosis, whether in
human medicine, auto mechanics, or electronic trouble-shooting.  Recent explorations
in this vein are exemplified by (Peng &amp; Reggia, 1990) and (O'Rorke, 1990).

But there is another reason why the factorization problem presents an especially
acute obstacle to progress in the system-theoretic approach to AI.  When the states
of a system are viewed as a manifold it is usual to imagine that everything factors
nicely into a base manifold and a remainder.  Smooth surfaces come to mind, a single
clear picture of a system that is immanently good for all time.  But this is how an
outside observer might see it, not how it appears to the inquiring system that is
located in a single point and has to discover, starting from there, the most fitting
description of its own space.  The proper division of a state vector into basic and
derivative factors is itself an item of knowledge to be discovered.  It constitutes
a piece of interpretive knowledge that has a large part in determining exactly how
an agent behaves.  The tentative hypotheses that an agent spins out with respect to
this issue will themselves need to be accommodated in a component of free space that
is well under control.  Without a stable theater of action for entertaining hypotheses,
an agent finds it difficult to sustain interest in the kinds of speculative bets that
are required to fund a complex inquiry.

States of information with respect to the placement of this fret or fulcrum can
vary with time.  Indeed, it is a goal of the knowledge directed system to leverage
this chordal node toward optimal possibilities, and this normally requires a continuing
interplay of experimental variations with attunement to the results.  Therefore it seems
necessary to develop a view of manifolds in which the location or depth of the primary
division that is effective in explaining behavior can vary from moment to moment.
The total phenomenal state of a system is its most fundamental reality, but the
way in which these states are connected to make a space, with information that
metes out distances, portrays curvatures, and binds fibers into bundles --
all this is an illusion projected onto the mist of individual states
from items of code in the knowledge component of the current state.
 
The mathematical and computational tools needed to implement such a perspective
goes beyond the understanding of systems and their spaces that I currently have
in my command.  It is considered bad form for a workman to blame his tools, but
in practical terms there continues to be room for better design.  The languages
and media that are made available do, indeed, make some things easier to see,
to say, and to do than others, whether it is English, Pascal (Wirth, 1976),
or Hopi (Whorf, 1956) that is being spoken.  A persistent attention to this
pragmatic factor in epistemology will be necessary to implement the brands
of knowledge-directed systems whose intelligence can function in real time.
To provide a computational language that can help to clarify these problems
is one of the chief theoretical tasks that I see for myself in the work ahead.

A system moving through a knowledge field would ideally be equipped with
a strategy for discovering the structure of that field to the greatest extent
possible.  That ideal strategy is a piece of knowledge, a segment of code existing
in the knowledge space of every point that has this option within its potential.
Does discovery mark only a different awareness of something that already exists,
a changed attitude toward a piece of knowledge already possessed?  Or can it be
something more substantial?  Are genuine invention and proper extensions of the
shared code possible?  Can intelligent systems acquire pieces of knowledge that
are not already in their possession, or in their potential to know?

If a piece of code is near at hand, within a small neighborhood of a system's place in
a knowledge field, then it is easy to see a relationship between adherence and discovery.
It is possible to picture how crumbs of code could be traced back, accumulated, and gradually
reassembled into whole slices of the desired program.  But what if the required code is more
distant?  If a system is observed in fact to drift toward increasing states of knowledge,
does its disposition toward knowledge as a goal need to be explained by some inherent
attraction of knowledge?  Do potential fields and propagating influences have to be
imagined in order to explain the apparent action at a distance?  Do massive bodies
of knowledge then naturally form, and eventually come to dominate whole knowledge
fields?  Are some bodies of knowledge intrinsically more attractive than others?
Can inquiries get so serious that they start to radiate gravity?

Questions like these are only ways of probing the range of possible systems that
are implied by the definition of a knowledge field.  What abstract possibility best
describes a given concrete system is a separate, empirical question.  With luck, the
human situation will be found among the reasonably learnable universes, but before that
hope can be evaluated a lot remains to be discovered about what, in fact, may be learnable
and reasonable.

¤~~~~~~~~~¤~~~~~~~~~¤~SECRUOS~EVIHCRA~¤~~~~~~~~~¤~~~~~~~~~¤

To Be Continued ...

Jon Awbrey

¤~~~~~~~~~¤~~~~~~~~~¤~~~~~~~~~¤~~~~~~~~~¤~~~~~~~~~¤

</PRE>

<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
<hr>
<!--X-Follow-Ups-End-->
<!--X-References-->
<ul><li><strong>References</strong>:
<ul>
<li><strong><a name="00272" href="msg00272.html">SUO: Inquiry Driven Systems</a></strong>
<ul><li><em>From:</em> Jon Awbrey &lt;jawbrey@oakland.edu&gt;</li></ul></li>
<li><strong><a name="00273" href="msg00273.html">SUO: Re: Inquiry Driven Systems</a></strong>
<ul><li><em>From:</em> Jon Awbrey &lt;jawbrey@oakland.edu&gt;</li></ul></li>
<li><strong><a name="00276" href="msg00276.html">SUO: Re: Inquiry Driven Systems</a></strong>
<ul><li><em>From:</em> Jon Awbrey &lt;jawbrey@oakland.edu&gt;</li></ul></li>
<li><strong><a name="00279" href="msg00279.html">SUO: Re: Inquiry Driven Systems</a></strong>
<ul><li><em>From:</em> Jon Awbrey &lt;jawbrey@oakland.edu&gt;</li></ul></li>
<li><strong><a name="00289" href="msg00289.html">SUO: Re: Inquiry Driven Systems</a></strong>
<ul><li><em>From:</em> Jon Awbrey &lt;jawbrey@oakland.edu&gt;</li></ul></li>
</ul></li></ul>
<!--X-References-End-->
<!--X-BotPNI-->
<ul>
<LI>Prev by Date:
<STRONG><A HREF="msg00292.html">SUO: Re: Axes</A></STRONG>
</LI>
<LI>Next by Date:
<STRONG><A HREF="msg00290.html">Re: SUO: RE: suggested draft vertebrate animal Ontology.</A></STRONG>
</LI>
<li>Prev by thread:
<strong><a href="msg00289.html">SUO: Re: Inquiry Driven Systems</a></strong>
</li>
<li>Next by thread:
<strong><a href="msg01535.html">SUO: Inquiry Driven Systems</a></strong>
</li>
<li>Index(es):
<ul>
<li><a href="mail85.html#00291"><strong>Date</strong></a></li>
<li><a href="thrd82.html#00291"><strong>Thread</strong></a></li>
</ul>
</li>
</ul>

<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
</body>
</html>
